# Task 01 – Text Generation with GPT-2

This is my submission for Task 1 of the Generative AI internship at Prodigy InfoToc.

## What I Did
- Fine-tuned a GPT-2 model using a small custom dataset
- Learned how text tokenization and model training works
- Used Google Colab and Hugging Face Transformers for the implementation

## Tools Used
- Python
- Google Colab
- Hugging Face Transformers

## Sample Output
> AI is a company that has been working on a new way to make the Internet more accessible to everyone...

## File
- `PRODIGY_INFOTOC_Task01_GPT2.ipynb` – Notebook with full code and steps

